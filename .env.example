# CancTool 环境变量配置示例
# 复制此文件为 .env 并根据需要修改配置

# =============================================================================
# 服务配置
# =============================================================================

# 代理服务API密钥（可选，用于保护服务）
# 如果设置，客户端需要在请求头中包含 Authorization: Bearer <SERVICE_API_KEY>
# 设置后，所有API端点都需要认证（除了 /health 和 /）
SERVICE_API_KEY=your-service-api-key-here

# 请求超时时间（秒）
REQUEST_TIMEOUT=30

# 最大重试次数
MAX_RETRIES=3

# 日志级别 (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Token流式输出配置
# STREAM_TOKEN_DELAY=0.03  # 每个token之间的延迟（秒）
# STREAM_CHUNK_SIZE=1      # 每次发送的token数量

# =============================================================================
# 多提供商配置
# =============================================================================

# 方式1: 使用配置文件（推荐）
LLM_PROVIDERS_CONFIG_FILE=providers_config.json

# 方式2: 使用JSON环境变量
# LLM_PROVIDERS_CONFIG={"default_provider": "openai", "providers": {...}}

# =============================================================================
# LLM提供商API密钥
# =============================================================================

# OpenAI API密钥
# OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API密钥
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Azure OpenAI API密钥
# AZURE_OPENAI_API_KEY=your-azure-openai-api-key-here

# =============================================================================
# 传统配置（向后兼容）
# =============================================================================

# 如果不使用多提供商配置，可以使用以下传统配置
# LLM API 基础URL
# LLM_API_BASE_URL=http://localhost:8000

# LLM API 密钥
# LLM_API_KEY=your-api-key-here

# 默认模型名称
# DEFAULT_MODEL_NAME=default