# CancTool - LLM Tool Call Wrapper Service

ä¸€ä¸ªé€šè¿‡æç¤ºè¯å·¥ç¨‹è®©ä¸æ”¯æŒOpenAIå·¥å…·è°ƒç”¨çš„LLMèƒ½å¤Ÿæ¨¡æ‹Ÿæ ‡å‡†OpenAIå·¥å…·è°ƒç”¨å“åº”çš„æœåŠ¡ï¼Œæ”¯æŒå¤šæä¾›å•†å’Œå¤šæ¨¡å‹é…ç½®ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

- âœ… **OpenAI APIå…¼å®¹**: å®Œå…¨å…¼å®¹OpenAI APIçš„èŠå¤©è¡¥å…¨æ¥å£
- âœ… **æ™ºèƒ½æµå¼è¾“å‡º**: è‡ªé€‚åº”çš„å¯é æµå¼å“åº”ï¼Œæ”¯æŒå¤šè¯­è¨€æ— ä¹±ç 
- âœ… **å·¥å…·è°ƒç”¨æ”¯æŒ**: æ”¯æŒå·¥å…·è°ƒç”¨ï¼ˆtool callingï¼‰å’Œå·¥å…·ç»“æœå¤„ç†
- âœ… **å¤šæä¾›å•†æ”¯æŒ**: æ”¯æŒå¤šä¸ªLLMæä¾›å•†ï¼ˆOpenAIã€Anthropicã€æœ¬åœ°LLMç­‰ï¼‰
- âœ… **å¤šæ¨¡å‹é…ç½®**: çµæ´»çš„æ¨¡å‹é…ç½®å’ŒåŠ¨æ€æ¨¡å‹åˆ—è¡¨
- âœ… **APIå¯†é’¥è®¤è¯**: å†…ç½®APIå¯†é’¥è®¤è¯æœºåˆ¶
- âœ… **é…ç½®åŒ–æ¨¡å‹åˆ—è¡¨**: `/v1/models`ç«¯ç‚¹è¿”å›å¯é…ç½®çš„æ¨¡å‹åˆ—è¡¨
- âœ… **æ™ºèƒ½æç¤ºè¯å·¥ç¨‹**: åŸºäºæç¤ºè¯å·¥ç¨‹çš„å·¥å…·è°ƒç”¨æ¨¡æ‹Ÿ
- âœ… **è‡ªåŠ¨è¯·æ±‚è¯†åˆ«**: è‡ªåŠ¨è¯†åˆ«è¯·æ±‚ç±»å‹å¹¶ç›¸åº”å¤„ç†
- âœ… **å®Œæ•´é”™è¯¯å¤„ç†**: å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œä¼˜åŒ–çš„æ—¥å¿—è®°å½•
- âœ… **é‡è¯•æœºåˆ¶**: å†…ç½®é‡è¯•æœºåˆ¶å’Œè¶…æ—¶æ§åˆ¶
- âœ… **PythonåŒ…**: å¯é€šè¿‡pipå®‰è£…çš„å®Œæ•´PythonåŒ…

## ğŸ“¦ å®‰è£…

### ç³»ç»Ÿè¦æ±‚

- Python >= 3.8.1
- æ¨èä½¿ç”¨ Python 3.9+ ä»¥è·å¾—æœ€ä½³å…¼å®¹æ€§

### é€šè¿‡pipå®‰è£…

```bash
pip install canctool
```

### ä»æºç å®‰è£…

```bash
git clone https://github.com/canctool/canctool.git
cd canctool
pip install -e .
```

### å¼€å‘ç¯å¢ƒå®‰è£…

```bash
# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# æˆ–è€…æ‰‹åŠ¨å®‰è£…å¼€å‘å·¥å…·
pip install pytest pytest-asyncio black isort
```

### éªŒè¯å®‰è£…

```bash
# è¿è¡ŒåŸºæœ¬æµ‹è¯•
python test_basic.py

# æˆ–è€…å¯åŠ¨æœåŠ¡æµ‹è¯•
canctool --help
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```bash
# å¯åŠ¨æœåŠ¡ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
canctool

# æˆ–è€…ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°
canctool --host 0.0.0.0 --port 8001 --log-level info
```

### 2. æµå¼è¾“å‡ºç¤ºä¾‹

```python
import requests
import json

# éæµå¼è¯·æ±‚
response = requests.post("http://localhost:8001/v1/chat/completions",
    headers={"Content-Type": "application/json"},
    json={
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": "Hello, how are you?"}],
        "stream": False
    }
)
print(response.json())

# æµå¼è¯·æ±‚
response = requests.post("http://localhost:8001/v1/chat/completions",
    headers={"Content-Type": "application/json"},
    json={
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": "Tell me a story"}],
        "stream": True
    },
    stream=True
)

for line in response.iter_lines():
    if line:
        line = line.decode('utf-8')
        if line.startswith('data: '):
            data = line[6:]  # Remove 'data: ' prefix
            if data == '[DONE]':
                break
            try:
                chunk = json.loads(data)
                content = chunk['choices'][0]['delta'].get('content', '')
                if content:
                    print(content, end='', flush=True)
            except json.JSONDecodeError:
                continue
print()  # New line at the end
```

### 3. é…ç½®å¤šæä¾›å•†

åˆ›å»º `providers_config.json` æ–‡ä»¶ï¼š

```json
{
  "default_provider": "openai",
  "providers": {
    "openai": {
      "base_url": "https://api.openai.com/v1",
      "api_key": "${OPENAI_API_KEY}",
      "models": ["gpt-4", "gpt-3.5-turbo"],
      "headers": {}
    },
    "local_llm": {
      "base_url": "http://localhost:8000",
      "api_key": null,
      "models": ["llama2-7b", "mistral-7b"],
      "headers": {}
    }
  }
}
```

### 4. è®¾ç½®ç¯å¢ƒå˜é‡

```bash
# è®¾ç½®LLMæä¾›å•†APIå¯†é’¥
export OPENAI_API_KEY="your-openai-api-key"
export ANTHROPIC_API_KEY="your-anthropic-api-key"

# è®¾ç½®ä»£ç†æœåŠ¡APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œç”¨äºä¿æŠ¤æœåŠ¡ï¼‰
export SERVICE_API_KEY="your-service-api-key"

# è®¾ç½®é…ç½®æ–‡ä»¶è·¯å¾„
export LLM_PROVIDERS_CONFIG_FILE="providers_config.json"

# è®¾ç½®æ—¥å¿—çº§åˆ«
export LOG_LEVEL="INFO"
```

### 5. ä»£ç†æœåŠ¡è®¤è¯

å¦‚æœè®¾ç½®äº† `SERVICE_API_KEY`ï¼Œå®¢æˆ·ç«¯éœ€è¦åœ¨è¯·æ±‚å¤´ä¸­åŒ…å«è®¤è¯ä¿¡æ¯ï¼š

```bash
# ä½¿ç”¨curlæµ‹è¯•
curl -H "Authorization: Bearer your-service-api-key" \
     http://localhost:8001/v1/models

# ä½¿ç”¨Python requests
import requests
headers = {"Authorization": "Bearer your-service-api-key"}
response = requests.get("http://localhost:8001/v1/models", headers=headers)
```

**æ³¨æ„**:
- å¦‚æœæœªè®¾ç½® `SERVICE_API_KEY`ï¼Œåˆ™ä¸éœ€è¦è®¤è¯
- è®¾ç½®åï¼Œæ‰€æœ‰APIç«¯ç‚¹éƒ½éœ€è¦è®¤è¯ï¼ˆé™¤äº† `/health` å’Œ `/`ï¼‰

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

1. **canctool/models.py** - æ•°æ®æ¨¡å‹å®šä¹‰
   - OpenAI APIå…¼å®¹çš„è¯·æ±‚/å“åº”æ¨¡å‹
   - å·¥å…·å®šä¹‰å’Œå‚æ•°æ¨¡å‹
   - æ¶ˆæ¯å’Œé€‰é¡¹æ¨¡å‹

2. **canctool/config.py** - å¤šæä¾›å•†é…ç½®ç®¡ç†
   - å¤šæä¾›å•†é…ç½®åŠ è½½å’ŒéªŒè¯
   - æ¨¡å‹åˆ°æä¾›å•†çš„æ˜ å°„
   - ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶æ”¯æŒ

3. **canctool/prompt_engineering.py** - æç¤ºè¯å·¥ç¨‹æœåŠ¡
   - å·¥å…·è°ƒç”¨æç¤ºè¯æ¨¡æ¿
   - å·¥å…·ç»“æœå¤„ç†æç¤ºè¯
   - LLMå“åº”è§£æå’Œæ ¼å¼åŒ–

4. **canctool/llm_service.py** - LLMæœåŠ¡æ¥å£
   - å¤šæä¾›å•†LLMé€šä¿¡æ¥å£
   - æ™ºèƒ½æä¾›å•†é€‰æ‹©å’Œè·¯ç”±
   - è¯·æ±‚ç±»å‹åˆ¤æ–­å’Œå¤„ç†é€»è¾‘

5. **canctool/response_formatter.py** - å“åº”æ ¼å¼åŒ–æœåŠ¡
   - æ ‡å‡†OpenAIæ ¼å¼å“åº”ç”Ÿæˆ
   - å·¥å…·è°ƒç”¨å“åº”æ ¼å¼åŒ–
   - ç»Ÿä¸€å“åº”å¤„ç†

6. **main.py** - FastAPIåº”ç”¨å…¥å£
   - APIè·¯ç”±å’Œç«¯ç‚¹
   - è®¤è¯ä¸­é—´ä»¶
   - å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—

## å®‰è£…å’Œé…ç½®

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

å¤åˆ¶ `.env.example` ä¸º `.env` å¹¶ä¿®æ”¹é…ç½®ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```env
# LLM API é…ç½®
LLM_API_BASE_URL=http://localhost:8000
LLM_API_KEY=your_api_key_here
DEFAULT_MODEL_NAME=default
REQUEST_TIMEOUT=30
MAX_RETRIES=3
LOG_LEVEL=INFO
```

### 3. é…ç½®è¯´æ˜

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `LLM_API_BASE_URL` | LLM APIçš„åŸºç¡€URL | `http://localhost:8000`, `https://api.openai.com/v1` |
| `LLM_API_KEY` | LLM APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰ | `sk-your-openai-api-key` |
| `DEFAULT_MODEL_NAME` | é»˜è®¤æ¨¡å‹åç§° | `gpt-3.5-turbo`, `claude-3-sonnet` |
| `REQUEST_TIMEOUT` | è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ | `30` |
| `MAX_RETRIES` | æœ€å¤§é‡è¯•æ¬¡æ•° | `3` |
| `LOG_LEVEL` | æ—¥å¿—çº§åˆ« | `DEBUG`, `INFO`, `WARNING`, `ERROR` |

### 4. æ”¯æŒçš„LLM APIæ ¼å¼

æœåŠ¡æ”¯æŒå¤šç§LLM APIæ ¼å¼ï¼š

#### OpenAIå…¼å®¹æ ¼å¼
```
POST /chat/completions
{
  "model": "model-name",
  "messages": [{"role": "user", "content": "prompt"}],
  "max_tokens": 1000,
  "temperature": 0.7
}
```

#### é€šç”¨ç”Ÿæˆæ ¼å¼
```
POST /generate
{
  "model": "model-name",
  "prompt": "prompt",
  "max_tokens": 1000,
  "temperature": 0.7
}
```

### 5. å¯åŠ¨æœåŠ¡

```bash
python main.py
```

æœåŠ¡å°†åœ¨ `http://localhost:8000` å¯åŠ¨ã€‚

### 6. è¿è¡Œæµ‹è¯•

```bash
python test_client.py
```

## å·¥ä½œæµç¨‹

### 1. å·¥å…·è°ƒç”¨æµç¨‹
```
ç”¨æˆ·è¯·æ±‚ â†’ åˆ¤æ–­éœ€è¦å·¥å…·è°ƒç”¨ â†’ æ„å»ºå·¥å…·è°ƒç”¨æç¤ºè¯ â†’ è°ƒç”¨LLM â†’ è§£æLLMå“åº” â†’ æ ¼å¼åŒ–ä¸ºæ ‡å‡†å·¥å…·è°ƒç”¨å“åº”
```

### 2. å·¥å…·ç»“æœå¤„ç†æµç¨‹
```
å·¥å…·ç»“æœ â†’ è¯†åˆ«ä¸ºç»“æœå¤„ç†è¯·æ±‚ â†’ æ„å»ºç»“æœå¤„ç†æç¤ºè¯ â†’ è°ƒç”¨LLM â†’ ç”Ÿæˆæœ€ç»ˆå›ç­” â†’ è¿”å›æ ‡å‡†å“åº”
```

### 3. æ™®é€šå¯¹è¯æµç¨‹
```
ç”¨æˆ·è¯·æ±‚ â†’ è¯†åˆ«ä¸ºæ™®é€šè¯·æ±‚ â†’ æ„å»ºå¯¹è¯æç¤ºè¯ â†’ è°ƒç”¨LLM â†’ è¿”å›æ ‡å‡†å“åº”
```

## ğŸ”Œ APIæ¥å£

### POST /v1/chat/completions
å…¼å®¹OpenAI APIçš„èŠå¤©è¡¥å…¨æ¥å£ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨å’Œæµå¼è¾“å‡ºã€‚

**è®¤è¯**: å¯é€‰ï¼ˆå¦‚æœè®¾ç½®äº†`SERVICE_API_KEY`ï¼‰
**Headers**: `Authorization: Bearer <your-api-key>`

**æ”¯æŒçš„å‚æ•°**:
- `model`: æ¨¡å‹åç§°
- `messages`: æ¶ˆæ¯åˆ—è¡¨
- `temperature`: æ¸©åº¦å‚æ•° (0.0-2.0)
- `max_tokens`: æœ€å¤§tokenæ•°
- `tools`: å·¥å…·å®šä¹‰åˆ—è¡¨
- `tool_choice`: å·¥å…·é€‰æ‹©ç­–ç•¥
- `stream`: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º (true/false)

**Tokenæµå¼è¾“å‡ºç¤ºä¾‹**:
```bash
curl -X POST http://localhost:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Tell me a story"}],
    "stream": true
  }'
```

**æ™ºèƒ½æµå¼è¾“å‡ºç‰¹æ€§**:
- è‡ªé€‚åº”æµå¼æ¨¡å¼ï¼šæ ¹æ®å†…å®¹é•¿åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹å¼
- å¤šè¯­è¨€æ”¯æŒï¼šå®Œç¾æ”¯æŒä¸­æ–‡ã€emojiã€ç‰¹æ®Šå­—ç¬¦ï¼Œæ— ä¹±ç 
- å¤šç§æµå¼æ¨¡å¼ï¼šå•è¯çº§ã€å¥å­çº§ã€å­—ç¬¦çº§æµå¼è¾“å‡º
- å¯é ç¨³å®šï¼šé¿å…å¤æ‚çš„tokenç¼–ç é—®é¢˜ï¼Œç¡®ä¿è¾“å‡ºæ­£ç¡®æ€§

**æµå¼å“åº”æ ¼å¼**:
```
data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk","created":1677610602,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello"},"finish_reason":null}]}

data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk","created":1677610602,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"content":" there!"},"finish_reason":null}]}

data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk","created":1677610602,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: [DONE]
```

### GET /v1/models
è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œè¿”å›OpenAIå…¼å®¹çš„æ¨¡å‹åˆ—è¡¨æ ¼å¼ã€‚

**è®¤è¯**: å¯é€‰ï¼ˆå¦‚æœè®¾ç½®äº†`SERVICE_API_KEY`ï¼‰

**è¡Œä¸º**: åªè¿”å›é»˜è®¤æä¾›å•†ï¼ˆ`default_provider`ï¼‰çš„æ¨¡å‹åˆ—è¡¨

**å“åº”ç¤ºä¾‹**:
```json
{
  "object": "list",
  "data": [
    {
      "id": "gpt-4",
      "object": "model",
      "created": 1677610602,
      "owned_by": "openai",
      "permission": [],
      "root": "gpt-4",
      "parent": null
    },
    {
      "id": "gpt-3.5-turbo",
      "object": "model",
      "created": 1677610602,
      "owned_by": "openai",
      "permission": [],
      "root": "gpt-3.5-turbo",
      "parent": null
    }
  ]
}
```

**æ³¨æ„**:
- åªæ˜¾ç¤ºé…ç½®æ–‡ä»¶ä¸­ `default_provider` æŒ‡å®šçš„æä¾›å•†çš„æ¨¡å‹
- å¦‚æœéœ€è¦ä½¿ç”¨å…¶ä»–æä¾›å•†çš„æ¨¡å‹ï¼Œè¯·åœ¨èŠå¤©è¯·æ±‚ä¸­ç›´æ¥æŒ‡å®šæ¨¡å‹åç§°

#### è¯·æ±‚ç¤ºä¾‹ - å·¥å…·è°ƒç”¨
```json
{
  "model": "your-model",
  "messages": [
    {
      "role": "user",
      "content": "ç°åœ¨åŒ—äº¬æ—¶é—´æ˜¯å‡ ç‚¹ï¼Ÿ"
    }
  ],
  "temperature": 0.7,
  "max_tokens": 1000,
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_time",
        "description": "è·å–æŒ‡å®šæ—¶åŒºçš„å½“å‰æ—¶é—´",
        "parameters": {
          "type": "object",
          "properties": {
            "timezone": {
              "default": "UTC",
              "description": "æ—¶åŒºåç§°ï¼Œä¾‹å¦‚ï¼šUTC, Asia/Shanghai, America/New_York",
              "type": "string"
            }
          },
          "required": []
        }
      }
    }
  ],
  "tool_choice": "auto"
}
```

#### è¯·æ±‚ç¤ºä¾‹ - å·¥å…·ç»“æœå¤„ç†
```json
{
  "model": "your-model",
  "messages": [
    {
      "role": "user",
      "content": "ç°åœ¨åŒ—äº¬æ—¶é—´æ˜¯å‡ ç‚¹ï¼Ÿ"
    },
    {
      "role": "assistant",
      "content": "",
      "tool_calls": [
        {
          "id": "call_123",
          "type": "function",
          "function": {
            "name": "get_current_time",
            "arguments": "{\"timezone\": \"Asia/Shanghai\"}"
          }
        }
      ]
    },
    {
      "role": "tool",
      "content": "{\"timezone\": \"Asia/Shanghai\", \"current_time\": \"2025-08-12 13:30:01 CST\", \"timestamp\": 1754976601.004147, \"status\": \"success\"}",
      "tool_call_id": "call_123"
    }
  ],
  "temperature": 0.7,
  "max_tokens": 1000
}
```

### GET /health
å¥åº·æ£€æŸ¥æ¥å£ï¼Œè¿”å›æœåŠ¡çŠ¶æ€å’Œé…ç½®ä¿¡æ¯ã€‚

### GET /
æ ¹è·¯å¾„ï¼Œè¿”å›æœåŠ¡ä¿¡æ¯ã€‚

## âš™ï¸ é…ç½®è¯´æ˜

### å¤šæä¾›å•†é…ç½®

æ”¯æŒä¸‰ç§é…ç½®æ–¹å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰ï¼š

1. **ç¯å¢ƒå˜é‡JSONé…ç½®**:
```bash
export LLM_PROVIDERS_CONFIG='{"default_provider": "openai", "providers": {...}}'
```

2. **é…ç½®æ–‡ä»¶**:
```bash
export LLM_PROVIDERS_CONFIG_FILE="providers_config.json"
```

3. **ä¼ ç»Ÿç¯å¢ƒå˜é‡**ï¼ˆå‘åå…¼å®¹ï¼‰:
```bash
export LLM_API_BASE_URL="http://localhost:8000"
export LLM_API_KEY="your-api-key"
export DEFAULT_MODEL_NAME="default"
```

### é…ç½®æ–‡ä»¶æ ¼å¼

```json
{
  "default_provider": "openai",
  "providers": {
    "openai": {
      "base_url": "https://api.openai.com/v1",
      "api_key": "${OPENAI_API_KEY}",
      "models": ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"],
      "headers": {
        "User-Agent": "CancTool/1.0"
      }
    },
    "anthropic": {
      "base_url": "https://api.anthropic.com/v1",
      "api_key": "${ANTHROPIC_API_KEY}",
      "models": ["claude-3-opus-20240229", "claude-3-sonnet-20240229"],
      "headers": {
        "anthropic-version": "2023-06-01"
      }
    },
    "local_llm": {
      "base_url": "http://localhost:8000",
      "api_key": null,
      "models": ["llama2-7b", "llama2-13b", "mistral-7b"],
      "headers": {}
    }
  }
}
```

### ç¯å¢ƒå˜é‡

| å˜é‡å | æè¿° | é»˜è®¤å€¼ |
|--------|------|--------|
| `SERVICE_API_KEY` | æœåŠ¡APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰ | None |
| `LLM_PROVIDERS_CONFIG` | JSONæ ¼å¼çš„æä¾›å•†é…ç½® | None |
| `LLM_PROVIDERS_CONFIG_FILE` | é…ç½®æ–‡ä»¶è·¯å¾„ | providers_config.json |
| `REQUEST_TIMEOUT` | è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ | 30 |
| `MAX_RETRIES` | æœ€å¤§é‡è¯•æ¬¡æ•° | 3 |
| `LOG_LEVEL` | æ—¥å¿—çº§åˆ« | INFO |

## æ‰©å±•åŠŸèƒ½

### æ·»åŠ æ–°çš„å·¥å…·ç±»å‹
1. åœ¨ `models.py` ä¸­æ·»åŠ å·¥å…·å®šä¹‰
2. åœ¨ `prompt_engineering.py` ä¸­æ›´æ–°å·¥å…·æè¿°æ¨¡æ¿
3. åœ¨LLMæœåŠ¡ä¸­å®ç°å®é™…çš„å·¥å…·è°ƒç”¨é€»è¾‘

### æ”¯æŒæ›´å¤šLLMç‰¹æ€§
å¯ä»¥æ‰©å±•æç¤ºè¯æ¨¡æ¿ä»¥æ”¯æŒæ›´å¤šçš„LLMç‰¹æ€§ï¼Œå¦‚æµå¼å“åº”ã€å¤šæ¨¡æ€è¾“å…¥ç­‰ã€‚

### è‡ªå®šä¹‰APIæ ¼å¼
åœ¨ `llm_service.py` ä¸­æ·»åŠ æ–°çš„APIæ ¼å¼æ”¯æŒæ–¹æ³•ã€‚

## é”™è¯¯å¤„ç†

æœåŠ¡åŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼š
- ç½‘ç»œè¯·æ±‚å¼‚å¸¸å¤„ç†
- JSONè§£æå¼‚å¸¸å¤„ç†
- LLMæœåŠ¡è°ƒç”¨å¼‚å¸¸å¤„ç†
- å…¨å±€å¼‚å¸¸æ•è·å’Œå“åº”
- é‡è¯•æœºåˆ¶

## æ—¥å¿—è®°å½•

ä½¿ç”¨Pythonæ ‡å‡†æ—¥å¿—åº“ï¼Œæ”¯æŒä¸åŒæ—¥å¿—çº§åˆ«ï¼š
- `DEBUG`: è¯¦ç»†è°ƒè¯•ä¿¡æ¯
- `INFO`: ä¸€èˆ¬ä¿¡æ¯
- `WARNING`: è­¦å‘Šä¿¡æ¯
- `ERROR`: é”™è¯¯ä¿¡æ¯
- `CRITICAL`: ä¸¥é‡é”™è¯¯ä¿¡æ¯

## ğŸ”§ æ•…éšœæ’é™¤

### å®‰è£…é—®é¢˜

1. **Pythonç‰ˆæœ¬å…¼å®¹æ€§**
   ```bash
   # æ£€æŸ¥Pythonç‰ˆæœ¬
   python --version

   # ç¡®ä¿ç‰ˆæœ¬ >= 3.8.1
   # å¦‚æœç‰ˆæœ¬è¿‡ä½ï¼Œè¯·å‡çº§Python
   ```

2. **ä¾èµ–å†²çª**
   ```bash
   # ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # æˆ–
   venv\Scripts\activate     # Windows

   # é‡æ–°å®‰è£…
   pip install canctool
   ```

3. **å¼€å‘ä¾èµ–é—®é¢˜**
   ```bash
   # å¦‚æœå¼€å‘ä¾èµ–å®‰è£…å¤±è´¥ï¼Œå¯ä»¥å•ç‹¬å®‰è£…æ ¸å¿ƒåŒ…
   pip install canctool

   # ç„¶åæ‰‹åŠ¨å®‰è£…éœ€è¦çš„å¼€å‘å·¥å…·
   pip install pytest black isort
   ```

### è¿è¡Œæ—¶é—®é¢˜

1. **LLM APIè¿æ¥å¤±è´¥**
   - æ£€æŸ¥æä¾›å•†é…ç½®ä¸­çš„ `base_url`
   - ç¡®è®¤LLMæœåŠ¡æ­£åœ¨è¿è¡Œ
   - æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®

2. **APIå¯†é’¥é”™è¯¯**
   - æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥é…ç½®
   - ç¡®è®¤APIå¯†é’¥æœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿæƒé™
   - æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„å¯†é’¥æ ¼å¼

3. **è¯·æ±‚è¶…æ—¶**
   - å¢åŠ  `REQUEST_TIMEOUT` å€¼
   - æ£€æŸ¥LLMæœåŠ¡å“åº”æ—¶é—´
   - è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹

4. **å·¥å…·è°ƒç”¨è§£æå¤±è´¥**
   - æ£€æŸ¥LLMå“åº”æ ¼å¼
   - ç¡®è®¤æ¨¡å‹æ”¯æŒè‹±æ–‡æç¤ºè¯
   - è°ƒæ•´æ¸©åº¦å‚æ•°é™ä½éšæœºæ€§

5. **æ¨¡å‹ä¸å¯ç”¨**
   - æ£€æŸ¥ `/v1/models` ç«¯ç‚¹è¿”å›çš„æ¨¡å‹åˆ—è¡¨
   - ç¡®è®¤è¯·æ±‚çš„æ¨¡å‹åœ¨é…ç½®ä¸­å­˜åœ¨
   - æ£€æŸ¥æä¾›å•†å’Œæ¨¡å‹çš„æ˜ å°„å…³ç³»

### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
export LOG_LEVEL=DEBUG
canctool

# æˆ–è€…åœ¨å¯åŠ¨æ—¶æŒ‡å®š
canctool --log-level debug
```

### æµ‹è¯•è¿æ¥

```bash
# æµ‹è¯•åŸºæœ¬åŠŸèƒ½
python test_basic.py

# æµ‹è¯•APIç«¯ç‚¹
curl http://localhost:8001/health
curl http://localhost:8001/v1/models
```