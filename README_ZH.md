# CancTool - LLM Tool Call Wrapper Service

**Language / è¯­è¨€**: [English](README.md) | [ä¸­æ–‡](README_ZH.md)

ä¸€ä¸ªé€šè¿‡æç¤ºè¯å·¥ç¨‹è®©ä¸æ”¯æŒOpenAIå·¥å…·è°ƒç”¨çš„LLMèƒ½å¤Ÿæ¨¡æ‹Ÿæ ‡å‡†OpenAIå·¥å…·è°ƒç”¨å“åº”çš„æœåŠ¡ï¼Œæ”¯æŒå¤šæä¾›å•†å’Œå¤šæ¨¡å‹é…ç½®ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

- âœ… **OpenAI APIå…¼å®¹**: å®Œå…¨å…¼å®¹OpenAI APIçš„èŠå¤©è¡¥å…¨æ¥å£
- âœ… **å·¥å…·è°ƒç”¨æ”¯æŒ**: æ”¯æŒå·¥å…·è°ƒç”¨ï¼ˆtool callingï¼‰å’Œå·¥å…·ç»“æœå¤„ç†
- âœ… **å¤šæä¾›å•†æ”¯æŒ**: æ”¯æŒå¤šä¸ªLLMæä¾›å•†ï¼ˆOpenAIã€Anthropicã€æœ¬åœ°LLMç­‰ï¼‰
- âœ… **JSONé…ç½®**: çµæ´»çš„JSONé…ç½®æ–‡ä»¶ï¼Œæ”¯æŒå¤šæ¨¡å‹å’Œå¤šæä¾›å•†
- âœ… **å®Œæ•´é”™è¯¯å¤„ç†**: å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œä¼˜åŒ–çš„æ—¥å¿—è®°å½•

## ğŸ“¦ å®‰è£…

### ç³»ç»Ÿè¦æ±‚
- Python >= 3.8.1

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. é…ç½®æœåŠ¡

åˆ›å»º `providers_config.json` æ–‡ä»¶ï¼š

```json
{
  "default_provider": "openai",
  "service_config": {
    "log_level": "INFO",
    "request_timeout": 30,
    "max_retries": 3,
    "max_prompt_length": 200000,
    "service_api_key": "your-service-api-key"
  },
  "providers": {
    "openai": {
      "base_url": "https://api.openai.com/v1",
      "api_key": "${OPENAI_API_KEY}",
      "models": ["gpt-4", "gpt-3.5-turbo"],
      "headers": {}
    },
    "local_llm": {
      "base_url": "http://localhost:8000",
      "api_key": null,
      "models": ["llama2-7b", "mistral-7b"],
      "headers": {}
    }
  }
}
```

### 2. å¯åŠ¨æœåŠ¡

#### æ–¹å¼ä¸€ï¼šä»æºç å¯åŠ¨

```bash

git clone https://github.com/sligter/canctool.git
cd canctool
uv sync

uv run main.py
```

#### æ–¹å¼äºŒï¼šDockerå¯åŠ¨

```bash
# ä½¿ç”¨é¢„æ„å»ºé•œåƒ
docker run -d --name canctool-service \
  -p 8001:8001 \
  -v "${PWD}/providers_config.json:/app/providers_config.json:ro" \
  -e LOG_LEVEL=INFO \
  --restart unless-stopped \
  bradleylzh/canctool:latest
```

æˆ–è€…ä»æºç æ„å»ºï¼š

```bash
# æ„å»ºé•œåƒ
docker build -t canctool .

# å¯åŠ¨æœåŠ¡
docker run -d --name canctool-service \
  -p 8001:8001 \
  -v "${PWD}/providers_config.json:/app/providers_config.json:ro" \
  -e LOG_LEVEL=INFO \
  --restart unless-stopped \
  canctool
```

### 3. ä½¿ç”¨ç¤ºä¾‹

#### éæµå¼è¯·æ±‚

```python
import requests
import json

# éæµå¼è¯·æ±‚
response = requests.post("http://localhost:8001/v1/chat/completions",
    headers={"Content-Type": "application/json"},
    json={
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": "Hello, how are you?"}],
        "stream": False
    }
)
print(response.json())
```

#### æµå¼è¯·æ±‚

```python
# æµå¼è¯·æ±‚
response = requests.post("http://localhost:8001/v1/chat/completions",
    headers={"Content-Type": "application/json"},
    json={
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": "Tell me a story"}],
        "stream": True
    },
    stream=True
)

for line in response.iter_lines():
    if line:
        line = line.decode('utf-8')
        if line.startswith('data: '):
            data = line[6:]  # Remove 'data: ' prefix
            if data == '[DONE]':
                break
            try:
                chunk = json.loads(data)
                content = chunk['choices'][0]['delta'].get('content', '')
                if content:
                    print(content, end='', flush=True)
            except json.JSONDecodeError:
                continue
print()  # New line at the end
```

## ğŸ—ï¸ æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | æè¿° |
|------|------|
| **canctool/models.py** | OpenAI APIå…¼å®¹çš„æ•°æ®æ¨¡å‹ |
| **canctool/config.py** | JSONé…ç½®æ–‡ä»¶ç®¡ç†å’Œå¤šæä¾›å•†æ”¯æŒ |
| **canctool/prompt_engineering.py** | æ™ºèƒ½æç¤ºè¯å·¥ç¨‹å’Œå·¥å…·è°ƒç”¨æ¨¡æ¿ |
| **canctool/llm_service.py** | å¤šæä¾›å•†LLMé€šä¿¡æ¥å£ |
| **canctool/response_formatter.py** | æ ‡å‡†OpenAIæ ¼å¼å“åº”ç”Ÿæˆ |
| **canctool/token_streamer.py** | æ™ºèƒ½æµå¼è¾“å‡ºå’Œtokenè®¡ç®— |
| **main.py** | FastAPIåº”ç”¨å…¥å£ |

## ğŸ”Œ APIæ¥å£

### POST /v1/chat/completions
å…¼å®¹OpenAI APIçš„èŠå¤©è¡¥å…¨æ¥å£ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨å’Œæµå¼è¾“å‡ºã€‚

**æ”¯æŒçš„å‚æ•°**:
- `model`: æ¨¡å‹åç§°
- `messages`: æ¶ˆæ¯åˆ—è¡¨
- `temperature`: æ¸©åº¦å‚æ•° (0.0-2.0)
- `max_tokens`: æœ€å¤§tokenæ•°
- `tools`: å·¥å…·å®šä¹‰åˆ—è¡¨
- `tool_choice`: å·¥å…·é€‰æ‹©ç­–ç•¥
- `stream`: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º (true/false)

### GET /v1/models
è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œè¿”å›é…ç½®æ–‡ä»¶ä¸­é»˜è®¤æä¾›å•†çš„æ¨¡å‹åˆ—è¡¨ã€‚

### GET /health
å¥åº·æ£€æŸ¥æ¥å£ï¼Œè¿”å›æœåŠ¡çŠ¶æ€ã€‚

## ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹

### å·¥å…·è°ƒç”¨ç¤ºä¾‹

```json
{
  "model": "gpt-3.5-turbo",
  "messages": [{"role": "user", "content": "ç°åœ¨åŒ—äº¬æ—¶é—´æ˜¯å‡ ç‚¹ï¼Ÿ"}],
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_time",
        "description": "è·å–æŒ‡å®šæ—¶åŒºçš„å½“å‰æ—¶é—´",
        "parameters": {
          "type": "object",
          "properties": {
            "timezone": {"type": "string", "description": "æ—¶åŒºåç§°"}
          }
        }
      }
    }
  ]
}
```

### æµå¼è¾“å‡ºç¤ºä¾‹

```bash
curl -X POST http://localhost:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "è®²ä¸ªæ•…äº‹"}],
    "stream": true
  }'
```

## âš™ï¸ é…ç½®è¯´æ˜

### JSONé…ç½®æ–‡ä»¶

åˆ›å»º `providers_config.json` æ–‡ä»¶æ¥é…ç½®å¤šæä¾›å•†ï¼š

```json
{
  "default_provider": "openai",
  "providers": {
    "openai": {
      "base_url": "https://api.openai.com/v1",
      "api_key": "${OPENAI_API_KEY}",
      "models": ["gpt-4", "gpt-3.5-turbo"],
      "headers": {}
    },
    "anthropic": {
      "base_url": "https://api.anthropic.com/v1",
      "api_key": "${ANTHROPIC_API_KEY}",
      "models": ["claude-3-sonnet-20240229"],
      "headers": {"anthropic-version": "2023-06-01"}
    },
    "local_llm": {
      "base_url": "http://localhost:8000",
      "api_key": null,
      "models": ["llama2-7b", "mistral-7b"],
      "headers": {}
    }
  }
}
```

## ğŸ”§ ç‰¹æ€§è¯´æ˜

### å·¥å…·è°ƒç”¨æ”¯æŒ
- è‡ªåŠ¨è¯†åˆ«å·¥å…·è°ƒç”¨è¯·æ±‚
- æ™ºèƒ½æç¤ºè¯å·¥ç¨‹ï¼Œæé«˜å·¥å…·è°ƒç”¨æˆåŠŸç‡
- æ”¯æŒå·¥å…·ç»“æœå¤„ç†å’Œæœ€ç»ˆå›ç­”ç”Ÿæˆ
- å®Œå…¨å…¼å®¹OpenAIå·¥å…·è°ƒç”¨æ ¼å¼

### å¤šæä¾›å•†æ¶æ„
- çµæ´»çš„JSONé…ç½®æ–‡ä»¶
- æ”¯æŒå¤šä¸ªLLMæä¾›å•†åŒæ—¶é…ç½®
- æ™ºèƒ½æ¨¡å‹è·¯ç”±å’Œæä¾›å•†é€‰æ‹©
- ç¯å¢ƒå˜é‡æ”¯æŒï¼Œä¾¿äºéƒ¨ç½²

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. LLM APIè¿æ¥å¤±è´¥
- æ£€æŸ¥ `providers_config.json` ä¸­çš„ `base_url`
- ç¡®è®¤LLMæœåŠ¡æ­£åœ¨è¿è¡Œ
- æ£€æŸ¥ç½‘ç»œè¿æ¥

#### 2. APIå¯†é’¥é”™è¯¯
- æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥
- ç¡®è®¤APIå¯†é’¥æœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿæƒé™

#### 3. æ¨¡å‹ä¸å¯ç”¨
- æ£€æŸ¥ `/v1/models` ç«¯ç‚¹è¿”å›çš„æ¨¡å‹åˆ—è¡¨
- ç¡®è®¤è¯·æ±‚çš„æ¨¡å‹åœ¨é…ç½®æ–‡ä»¶ä¸­å­˜åœ¨

### æµ‹è¯•è¿æ¥

```bash
# æµ‹è¯•APIç«¯ç‚¹
curl http://localhost:8001/health
curl http://localhost:8001/v1/models
```

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œè¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤ [GitHub Issue](https://github.com/sligter/canctool/issues)